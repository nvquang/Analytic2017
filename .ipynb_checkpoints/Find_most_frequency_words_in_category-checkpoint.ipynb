{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"data/training/data_train.csv\", dtype='unicode')\n",
    "data_df.fillna(value='', inplace=True)\n",
    "data_df = data_df.apply(lambda x: x.astype(str).str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_df[['clarity','conciseness']] = data_df[['clarity','conciseness']].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cleanhtml(raw_html):\n",
    "    result = re.sub(re.compile('<.*?>'), ' ', raw_html)\n",
    "    return result\n",
    "data_df['short_description_clear_html'] = data_df.apply(lambda row: cleanhtml(row['short_description']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# train_df, test_df = train_test_split(data_df, test_size = 0.2)\n",
    "train_df = data_df\n",
    "test_df = pd.read_csv(\"data/validation/data_valid_2.csv\")\n",
    "test_df.fillna(value='', inplace=True)\n",
    "test_df = test_df.apply(lambda x: x.astype(str).str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>country</td>\n",
       "      <td>sku_id</td>\n",
       "      <td>title</td>\n",
       "      <td>category_lvl_1</td>\n",
       "      <td>category_lvl_2</td>\n",
       "      <td>category_lvl_3</td>\n",
       "      <td>short_description</td>\n",
       "      <td>price</td>\n",
       "      <td>product_type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my</td>\n",
       "      <td>ap564elasstwanmy</td>\n",
       "      <td>apple macbook pro mgxc2zp/a 16gb i7 15.4-inch ...</td>\n",
       "      <td>computers &amp; laptops</td>\n",
       "      <td>laptops</td>\n",
       "      <td>macbooks</td>\n",
       "      <td>os x lion&lt;br&gt; intel core i7&lt;br&gt; 15-inch retina...</td>\n",
       "      <td>12550</td>\n",
       "      <td>local</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my</td>\n",
       "      <td>br924hbaa5b3tlanmy</td>\n",
       "      <td>brand's® american ginseng triple pack (3x 6's)...</td>\n",
       "      <td>health &amp; beauty</td>\n",
       "      <td>food supplements</td>\n",
       "      <td>well being</td>\n",
       "      <td>&lt;ul&gt; &lt;li&gt;traditionally used to calm the mind a...</td>\n",
       "      <td>105</td>\n",
       "      <td>local</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my</td>\n",
       "      <td>ca673elaa5ug3xanmy</td>\n",
       "      <td>canon eos m10 mirrorless digital camera 18mp w...</td>\n",
       "      <td>cameras</td>\n",
       "      <td>mirrorless</td>\n",
       "      <td></td>\n",
       "      <td>&lt;div&gt; &lt;ul&gt; &lt;li&gt;18.0mp aps-c cmos sensor&lt;/li&gt; &lt;...</td>\n",
       "      <td>1588</td>\n",
       "      <td>local</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>my</td>\n",
       "      <td>de759elaa7qm1xanmy</td>\n",
       "      <td>dell led monitor 23\" (e2316h)</td>\n",
       "      <td>computers &amp; laptops</td>\n",
       "      <td>computer accessories</td>\n",
       "      <td>monitors</td>\n",
       "      <td>&lt;div class=\"prod_content\"&gt; &lt;div class=\"prod_de...</td>\n",
       "      <td>565</td>\n",
       "      <td>local</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                   1  \\\n",
       "0  country              sku_id   \n",
       "1       my    ap564elasstwanmy   \n",
       "2       my  br924hbaa5b3tlanmy   \n",
       "3       my  ca673elaa5ug3xanmy   \n",
       "4       my  de759elaa7qm1xanmy   \n",
       "\n",
       "                                                   2                    3  \\\n",
       "0                                              title       category_lvl_1   \n",
       "1  apple macbook pro mgxc2zp/a 16gb i7 15.4-inch ...  computers & laptops   \n",
       "2  brand's® american ginseng triple pack (3x 6's)...      health & beauty   \n",
       "3  canon eos m10 mirrorless digital camera 18mp w...              cameras   \n",
       "4                      dell led monitor 23\" (e2316h)  computers & laptops   \n",
       "\n",
       "                      4               5  \\\n",
       "0        category_lvl_2  category_lvl_3   \n",
       "1               laptops        macbooks   \n",
       "2      food supplements      well being   \n",
       "3            mirrorless                   \n",
       "4  computer accessories        monitors   \n",
       "\n",
       "                                                   6      7             8  \n",
       "0                                  short_description  price  product_type  \n",
       "1  os x lion<br> intel core i7<br> 15-inch retina...  12550         local  \n",
       "2  <ul> <li>traditionally used to calm the mind a...    105         local  \n",
       "3  <div> <ul> <li>18.0mp aps-c cmos sensor</li> <...   1588         local  \n",
       "4  <div class=\"prod_content\"> <div class=\"prod_de...    565         local  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "full_categories_set = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for index, row in train_df.iterrows():\n",
    "    full_category = row['category_lvl_1'] + \"_\" + row['category_lvl_2'] \\\n",
    "        + \"_\" + row['category_lvl_3']\n",
    "    full_categories_set.add(full_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_bag_of_word(texts):\n",
    "    return [ collections.Counter(re.findall(r'\\w+', txt)) for txt in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clarity_word_most_frequence_dict = {}\n",
    "un_clarity_word_most_frequency_dict = {}\n",
    "conciseness_word_most_frequency_dict = {}\n",
    "un_conciseness_word_most_frequency_dict = {}\n",
    "\n",
    "\n",
    "stopwords_set = set(stopwords.words('english'))\n",
    "\n",
    "for full_category in full_categories_set:        \n",
    "\n",
    "    categories = full_category.split(sep=\"_\", maxsplit = 3)\n",
    "    category_level_1 = categories[0]\n",
    "    category_level_2 = categories[1]\n",
    "    category_level_3 = categories[2]\n",
    "    \n",
    "    ##------------ create dict for clairy product --------------------- #########\n",
    "    clarity_product_by_category = train_df[(train_df.category_lvl_1 == category_level_1) &\n",
    "                                   (train_df.category_lvl_2 == category_level_2) &\n",
    "                                   (train_df.category_lvl_3 == category_level_3) &\n",
    "                                   (train_df.clarity == 1)]\n",
    "    bag_of_words_title = create_bag_of_word([clarity_product_by_category.title.str.cat(sep=' ')])\n",
    "  \n",
    "    most_common_words = []\n",
    "    for word, count in bag_of_words_title[0].most_common():           \n",
    "        if (count > 10) & (not word.isnumeric()) & (word not in stopwords_set):\n",
    "            if category_level_1 == \"fashion\":\n",
    "                if word not in ['women', 'womens', 'girl', 'girls', 'woman'] and (count > 20):\n",
    "                    most_common_words.append(word)\n",
    "            else:\n",
    "                most_common_words.append(word)\n",
    "    \n",
    "    clarity_word_most_frequence_dict[full_category] = most_common_words\n",
    "    \n",
    "    ##------------ create dict for unclarify product -------------#######\n",
    "    \n",
    "\n",
    "    unclarity_product_by_category = train_df[(train_df.category_lvl_1 == category_level_1) &\n",
    "                                   (train_df.category_lvl_2 == category_level_2) &\n",
    "                                   (train_df.category_lvl_3 == category_level_3) &\n",
    "                                   (train_df.clarity == 0)]\n",
    "    bag_of_words_title = create_bag_of_word([unclarity_product_by_category.title.str.cat(sep=' ')])\n",
    "  \n",
    "    most_common_words = []\n",
    "    for word, count in bag_of_words_title[0].most_common():           \n",
    "        if (count > 10) & (not word.isnumeric()) & (word not in stopwords_set):\n",
    "            if category_level_1 == \"fashion\":\n",
    "                if word not in ['women', 'womens', 'girl', 'girls', 'woman'] and (count > 20):\n",
    "                    most_common_words.append(word)\n",
    "            else:\n",
    "                most_common_words.append(word)\n",
    "    \n",
    "    un_clarity_word_most_frequency_dict[full_category] = most_common_words\n",
    "    \n",
    "    ##--------------- create dict for conciseness ---------------------------------####\n",
    "    \n",
    "    conciseness_product_by_category = train_df[(train_df.category_lvl_1 == category_level_1) &\n",
    "                                   (train_df.category_lvl_2 == category_level_2) &\n",
    "                                   (train_df.category_lvl_3 == category_level_3) &\n",
    "                                   (train_df.conciseness == 1)]\n",
    "    \n",
    "    bag_of_words_title = create_bag_of_word([conciseness_product_by_category.title.str.cat(sep=' ')])\n",
    "    \n",
    "    most_common_words = []\n",
    "    for word, count in bag_of_words_title[0].most_common():           \n",
    "        if (count > 10) & (not word.isnumeric()) & (word not in stopwords_set):\n",
    "            most_common_words.append(word)\n",
    "    \n",
    "    conciseness_word_most_frequency_dict[full_category] = most_common_words\n",
    "    \n",
    "    ##--------------- create dict for unconciseness ---------------------------------####\n",
    "    \n",
    "    unconciseness_product_by_category = train_df[(train_df.category_lvl_1 == category_level_1) &\n",
    "                                   (train_df.category_lvl_2 == category_level_2) &\n",
    "                                   (train_df.category_lvl_3 == category_level_3) &\n",
    "                                   (train_df.conciseness == 0)]\n",
    "    \n",
    "    bag_of_words_title = create_bag_of_word([unconciseness_product_by_category.title.str.cat(sep=' ')])\n",
    "    \n",
    "    most_common_words = []\n",
    "    for word, count in bag_of_words_title[0].most_common(): \n",
    "        if (count > 10) & (not word.isnumeric()) & (word not in stopwords_set):\n",
    "            most_common_words.append(word)\n",
    "    \n",
    "    un_conciseness_word_most_frequency_dict[full_category] = most_common_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=  0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'category_lvl_1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3843)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.Int64HashTable.get_item (pandas/hashtable.c:6501)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: an integer is required",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-4e61353ccffe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"i= \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"row['category_lvl_1']: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category_lvl_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mfull_category\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category_lvl_1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category_lvl_2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category_lvl_3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/index.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   1788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1790\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1791\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minferred_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'integer'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'boolean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_value (pandas/index.c:3204)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_value (pandas/index.c:2903)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3908)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'category_lvl_1'"
     ]
    }
   ],
   "source": [
    "clarities_pred = np.zeros(len (test_df))\n",
    "conciseness_pred = np.zeros(len(test_df))\n",
    "\n",
    "clarity_wrong_cases_dict = {}\n",
    "conciseness_wrong_case_dict = {}\n",
    "\n",
    "i = 0\n",
    "for index, row in test_df.iterrows():\n",
    "    full_category = row['category_lvl_1'] + \"_\" + row['category_lvl_2'] + \"_\" + row['category_lvl_3']\n",
    "    \n",
    "    most_common_words_clarity = \\\n",
    "        clarity_word_most_frequence_dict.get(full_category)\n",
    "    most_common_words_unclarity = un_clarity_word_most_frequency_dict.get(full_category)  \n",
    "      \n",
    "    nb_of_match_clarity = 0\n",
    "    for word in row['title'].split():\n",
    "        if word in most_common_words_clarity:\n",
    "            nb_of_match_clarity += 1\n",
    "            \n",
    "            \n",
    "    nb_of_match_unclarity = 0\n",
    "    for word in row['title'].split():\n",
    "        if word in most_common_words_unclarity:\n",
    "            nb_of_match_unclarity += 1\n",
    "            \n",
    "    \n",
    "    if (nb_of_match_clarity == 0) & (nb_of_match_unclarity == 0):\n",
    "        clarities_pred[i] = 0.5\n",
    "    elif (nb_of_match_clarity > 0) & (nb_of_match_unclarity > 0) :\n",
    "        clarities_pred[i] = nb_of_match_clarity * 1.0 / (nb_of_match_clarity + nb_of_match_unclarity)\n",
    "    elif (nb_of_match_clarity > 0) & (nb_of_match_unclarity == 0):\n",
    "        clarities_pred[i] = 1\n",
    "    elif (nb_of_match_clarity == 0) & (nb_of_match_unclarity > 0):\n",
    "        clarities_pred[i] = 0\n",
    "        \n",
    "    if clarities_pred[i] == 0:\n",
    "        conciseness_pred[i] = 0\n",
    "    else:\n",
    "        most_common_words_conciseness = conciseness_word_most_frequency_dict.get(full_category)\n",
    "        most_common_words_unconciseness = un_conciseness_word_most_frequency_dict.get(full_category)\n",
    "        \n",
    "        nb_of_match_conciseness = 0\n",
    "        for word in row['title'].split():\n",
    "            if word in most_common_words_conciseness:\n",
    "                nb_of_match_conciseness += 1\n",
    "\n",
    "\n",
    "        nb_of_match_unconciseness = 0\n",
    "        for word in row['title'].split():\n",
    "            if word in most_common_words_unconciseness:\n",
    "                nb_of_match_unconciseness += 1\n",
    "                \n",
    "        if (nb_of_match_conciseness == 0) & (nb_of_match_unconciseness == 0):\n",
    "            conciseness_pred[i] = 0.5\n",
    "        elif (nb_of_match_conciseness > 0) & (nb_of_match_unconciseness > 0) :\n",
    "            conciseness_pred[i] = \\\n",
    "                    nb_of_match_conciseness * 1.0 / (nb_of_match_conciseness + nb_of_match_unconciseness)\n",
    "        elif (nb_of_match_conciseness > 0) & (nb_of_match_unconciseness == 0):\n",
    "            conciseness_pred[i] = 1\n",
    "        elif (nb_of_match_conciseness == 0) & (nb_of_match_unconciseness > 0):\n",
    "            conciseness_pred[i] = 0\n",
    "\n",
    "#     if clarities_pred[i] != row['clarity']:\n",
    "#         if categories_word_wrong_case_dict.get(full_category) == None:\n",
    "#             categories_word_wrong_case_dict[full_category] = 0\n",
    "#         categories_word_wrong_case_dict[full_category] += 1\n",
    "        \n",
    "#     if conciseness_pred[i] != row['conciseness']:\n",
    "#         if categories_word_wrong_case_conciseness_dict.get(full_category) == None:\n",
    "#             categories_word_wrong_case_conciseness_dict[full_category] = 0\n",
    "#         categories_word_wrong_case_conciseness_dict[full_category] += 1\n",
    "    \n",
    "    i = i + 1   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_error\n",
    "# clarity_error = np.sqrt(mean_squared_error(test_df.clarity.as_matrix(), clarities_pred))\n",
    "# conciseness_error = np.sqrt(mean_squared_error(test_df.conciseness.as_matrix(), conciseness_pred))\n",
    "\n",
    "# print(\"clarity_error: \", clarity_error)\n",
    "# print(\"conciseness_error: \", conciseness_error)\n",
    "# print(\"mean: \", np.mean([clarity_error, conciseness_error]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clarities_pred_df = pd.DataFrame(data = clarities_pred.tolist())\n",
    "clarities_pred_df.to_csv(\"clarities_pred.csv\", index = False)\n",
    "\n",
    "conciseness_pred_df = pd.DataFrame(data = conciseness_pred.tolist())\n",
    "conciseness_pred_df.to_csv(\"conciseness_pred.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
