{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"data/training/data_train.csv\", dtype='unicode')\n",
    "data_df.fillna(value='', inplace=True)\n",
    "data_df = data_df.apply(lambda x: x.astype(str).str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_df[['clarity','conciseness']] = data_df[['clarity','conciseness']].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cleanhtml(raw_html):\n",
    "    result = re.sub(re.compile('<.*?>'), ' ', raw_html)\n",
    "    return result\n",
    "data_df['short_description_clear_html'] = data_df.apply(lambda row: cleanhtml(row['short_description']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# train_df, test_df = train_test_split(data_df, test_size = 0.2)\n",
    "train_df = data_df\n",
    "test_df = pd.read_csv(\"data/validation/data_valid_2.csv\")\n",
    "test_df.fillna(value='', inplace=True)\n",
    "test_df = test_df.apply(lambda x: x.astype(str).str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>sku_id</th>\n",
       "      <th>title</th>\n",
       "      <th>category_lvl_1</th>\n",
       "      <th>category_lvl_2</th>\n",
       "      <th>category_lvl_3</th>\n",
       "      <th>short_description</th>\n",
       "      <th>price</th>\n",
       "      <th>product_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my</td>\n",
       "      <td>ap564elasstwanmy</td>\n",
       "      <td>apple macbook pro mgxc2zp/a 16gb i7 15.4-inch ...</td>\n",
       "      <td>computers &amp; laptops</td>\n",
       "      <td>laptops</td>\n",
       "      <td>macbooks</td>\n",
       "      <td>os x lion&lt;br&gt; intel core i7&lt;br&gt; 15-inch retina...</td>\n",
       "      <td>12550.0</td>\n",
       "      <td>local</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my</td>\n",
       "      <td>br924hbaa5b3tlanmy</td>\n",
       "      <td>brand's® american ginseng triple pack (3x 6's)...</td>\n",
       "      <td>health &amp; beauty</td>\n",
       "      <td>food supplements</td>\n",
       "      <td>well being</td>\n",
       "      <td>&lt;ul&gt; &lt;li&gt;traditionally used to calm the mind a...</td>\n",
       "      <td>105.0</td>\n",
       "      <td>local</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my</td>\n",
       "      <td>ca673elaa5ug3xanmy</td>\n",
       "      <td>canon eos m10 mirrorless digital camera 18mp w...</td>\n",
       "      <td>cameras</td>\n",
       "      <td>mirrorless</td>\n",
       "      <td></td>\n",
       "      <td>&lt;div&gt; &lt;ul&gt; &lt;li&gt;18.0mp aps-c cmos sensor&lt;/li&gt; &lt;...</td>\n",
       "      <td>1588.0</td>\n",
       "      <td>local</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my</td>\n",
       "      <td>de759elaa7qm1xanmy</td>\n",
       "      <td>dell led monitor 23\" (e2316h)</td>\n",
       "      <td>computers &amp; laptops</td>\n",
       "      <td>computer accessories</td>\n",
       "      <td>monitors</td>\n",
       "      <td>&lt;div class=\"prod_content\"&gt; &lt;div class=\"prod_de...</td>\n",
       "      <td>565.0</td>\n",
       "      <td>local</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>my</td>\n",
       "      <td>es802otaabhay8anmy</td>\n",
       "      <td>esprit tallac brave nubuck sand es107601001 be...</td>\n",
       "      <td>watches sunglasses jewellery</td>\n",
       "      <td>watches</td>\n",
       "      <td>men</td>\n",
       "      <td>&lt;ul&gt; &lt;li&gt;stainless steel case&lt;/li&gt; &lt;li&gt;mineral...</td>\n",
       "      <td>279.0</td>\n",
       "      <td>local</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country              sku_id  \\\n",
       "0      my    ap564elasstwanmy   \n",
       "1      my  br924hbaa5b3tlanmy   \n",
       "2      my  ca673elaa5ug3xanmy   \n",
       "3      my  de759elaa7qm1xanmy   \n",
       "4      my  es802otaabhay8anmy   \n",
       "\n",
       "                                               title  \\\n",
       "0  apple macbook pro mgxc2zp/a 16gb i7 15.4-inch ...   \n",
       "1  brand's® american ginseng triple pack (3x 6's)...   \n",
       "2  canon eos m10 mirrorless digital camera 18mp w...   \n",
       "3                      dell led monitor 23\" (e2316h)   \n",
       "4  esprit tallac brave nubuck sand es107601001 be...   \n",
       "\n",
       "                 category_lvl_1        category_lvl_2 category_lvl_3  \\\n",
       "0           computers & laptops               laptops       macbooks   \n",
       "1               health & beauty      food supplements     well being   \n",
       "2                       cameras            mirrorless                  \n",
       "3           computers & laptops  computer accessories       monitors   \n",
       "4  watches sunglasses jewellery               watches            men   \n",
       "\n",
       "                                   short_description    price product_type  \n",
       "0  os x lion<br> intel core i7<br> 15-inch retina...  12550.0        local  \n",
       "1  <ul> <li>traditionally used to calm the mind a...    105.0        local  \n",
       "2  <div> <ul> <li>18.0mp aps-c cmos sensor</li> <...   1588.0        local  \n",
       "3  <div class=\"prod_content\"> <div class=\"prod_de...    565.0        local  \n",
       "4  <ul> <li>stainless steel case</li> <li>mineral...    279.0        local  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "full_categories_set = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for index, row in train_df.iterrows():\n",
    "    full_category = row['category_lvl_1'] + \"_\" + row['category_lvl_2'] \\\n",
    "        + \"_\" + row['category_lvl_3']\n",
    "    full_categories_set.add(full_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_bag_of_word(texts):\n",
    "    return [ collections.Counter(re.findall(r'\\w+', txt)) for txt in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clarity_word_most_frequence_dict = {}\n",
    "un_clarity_word_most_frequency_dict = {}\n",
    "conciseness_word_most_frequency_dict = {}\n",
    "un_conciseness_word_most_frequency_dict = {}\n",
    "\n",
    "\n",
    "stopwords_set = set(stopwords.words('english'))\n",
    "\n",
    "for full_category in full_categories_set:        \n",
    "\n",
    "    categories = full_category.split(sep=\"_\", maxsplit = 3)\n",
    "    category_level_1 = categories[0]\n",
    "    category_level_2 = categories[1]\n",
    "    category_level_3 = categories[2]\n",
    "    \n",
    "    ##------------ create dict for clairy product --------------------- #########\n",
    "    clarity_product_by_category = train_df[(train_df.category_lvl_1 == category_level_1) &\n",
    "                                   (train_df.category_lvl_2 == category_level_2) &\n",
    "                                   (train_df.category_lvl_3 == category_level_3) &\n",
    "                                   (train_df.clarity == 1)]\n",
    "    bag_of_words_title = create_bag_of_word([clarity_product_by_category.title.str.cat(sep=' ')])\n",
    "  \n",
    "    most_common_words = []\n",
    "    for word, count in bag_of_words_title[0].most_common():           \n",
    "        if (count > 10) & (not word.isnumeric()) & (word not in stopwords_set):\n",
    "            if category_level_1 == \"fashion\":\n",
    "                if word not in ['women', 'womens', 'girl', 'girls', 'woman'] and (count > 20):\n",
    "                    most_common_words.append(word)\n",
    "            else:\n",
    "                most_common_words.append(word)\n",
    "    \n",
    "    clarity_word_most_frequence_dict[full_category] = most_common_words\n",
    "    \n",
    "    ##------------ create dict for unclarify product -------------#######\n",
    "    \n",
    "\n",
    "    unclarity_product_by_category = train_df[(train_df.category_lvl_1 == category_level_1) &\n",
    "                                   (train_df.category_lvl_2 == category_level_2) &\n",
    "                                   (train_df.category_lvl_3 == category_level_3) &\n",
    "                                   (train_df.clarity == 0)]\n",
    "    bag_of_words_title = create_bag_of_word([unclarity_product_by_category.title.str.cat(sep=' ')])\n",
    "  \n",
    "    most_common_words = []\n",
    "    for word, count in bag_of_words_title[0].most_common():           \n",
    "        if (count > 10) & (not word.isnumeric()) & (word not in stopwords_set):\n",
    "            if category_level_1 == \"fashion\":\n",
    "                if word not in ['women', 'womens', 'girl', 'girls', 'woman'] and (count > 20):\n",
    "                    most_common_words.append(word)\n",
    "            else:\n",
    "                most_common_words.append(word)\n",
    "    \n",
    "    un_clarity_word_most_frequency_dict[full_category] = most_common_words\n",
    "    \n",
    "    ##--------------- create dict for conciseness ---------------------------------####\n",
    "    \n",
    "    conciseness_product_by_category = train_df[(train_df.category_lvl_1 == category_level_1) &\n",
    "                                   (train_df.category_lvl_2 == category_level_2) &\n",
    "                                   (train_df.category_lvl_3 == category_level_3) &\n",
    "                                   (train_df.conciseness == 1)]\n",
    "    \n",
    "    bag_of_words_title = create_bag_of_word([conciseness_product_by_category.title.str.cat(sep=' ')])\n",
    "    \n",
    "    most_common_words = []\n",
    "    for word, count in bag_of_words_title[0].most_common():           \n",
    "        if (count > 10) & (not word.isnumeric()) & (word not in stopwords_set):\n",
    "            most_common_words.append(word)\n",
    "    \n",
    "    conciseness_word_most_frequency_dict[full_category] = most_common_words\n",
    "    \n",
    "    ##--------------- create dict for unconciseness ---------------------------------####\n",
    "    \n",
    "    unconciseness_product_by_category = train_df[(train_df.category_lvl_1 == category_level_1) &\n",
    "                                   (train_df.category_lvl_2 == category_level_2) &\n",
    "                                   (train_df.category_lvl_3 == category_level_3) &\n",
    "                                   (train_df.conciseness == 0)]\n",
    "    \n",
    "    bag_of_words_title = create_bag_of_word([unconciseness_product_by_category.title.str.cat(sep=' ')])\n",
    "    \n",
    "    most_common_words = []\n",
    "    for word, count in bag_of_words_title[0].most_common(): \n",
    "        if (count > 10) & (not word.isnumeric()) & (word not in stopwords_set):\n",
    "            most_common_words.append(word)\n",
    "    \n",
    "    un_conciseness_word_most_frequency_dict[full_category] = most_common_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clarities_pred = np.zeros(len (test_df))\n",
    "conciseness_pred = np.zeros(len(test_df))\n",
    "\n",
    "clarity_wrong_cases_dict = {}\n",
    "conciseness_wrong_case_dict = {}\n",
    "\n",
    "i = 0\n",
    "for index, row in test_df.iterrows():\n",
    "    full_category = row['category_lvl_1'] + \"_\" + row['category_lvl_2'] + \"_\" + row['category_lvl_3']\n",
    "    \n",
    "    most_common_words_clarity = \\\n",
    "        clarity_word_most_frequence_dict.get(full_category)\n",
    "    most_common_words_unclarity = un_clarity_word_most_frequency_dict.get(full_category)  \n",
    "      \n",
    "    nb_of_match_clarity = 0\n",
    "    for word in row['title'].split():\n",
    "        if word in most_common_words_clarity:\n",
    "            nb_of_match_clarity += 1\n",
    "            \n",
    "            \n",
    "    nb_of_match_unclarity = 0\n",
    "    for word in row['title'].split():\n",
    "        if word in most_common_words_unclarity:\n",
    "            nb_of_match_unclarity += 1\n",
    "            \n",
    "    \n",
    "    if (nb_of_match_clarity == 0) & (nb_of_match_unclarity == 0):\n",
    "        clarities_pred[i] = 0.5\n",
    "    elif (nb_of_match_clarity > 0) & (nb_of_match_unclarity > 0) :\n",
    "        clarities_pred[i] = nb_of_match_clarity * 1.0 / (nb_of_match_clarity + nb_of_match_unclarity)\n",
    "    elif (nb_of_match_clarity > 0) & (nb_of_match_unclarity == 0):\n",
    "        clarities_pred[i] = 1\n",
    "    elif (nb_of_match_clarity == 0) & (nb_of_match_unclarity > 0):\n",
    "        clarities_pred[i] = 0\n",
    "        \n",
    "    if clarities_pred[i] == 0:\n",
    "        conciseness_pred[i] = 0\n",
    "    else:\n",
    "        most_common_words_conciseness = conciseness_word_most_frequency_dict.get(full_category)\n",
    "        most_common_words_unconciseness = un_conciseness_word_most_frequency_dict.get(full_category)\n",
    "        \n",
    "        nb_of_match_conciseness = 0\n",
    "        for word in row['title'].split():\n",
    "            if word in most_common_words_conciseness:\n",
    "                nb_of_match_conciseness += 1\n",
    "\n",
    "\n",
    "        nb_of_match_unconciseness = 0\n",
    "        for word in row['title'].split():\n",
    "            if word in most_common_words_unconciseness:\n",
    "                nb_of_match_unconciseness += 1\n",
    "                \n",
    "        if (nb_of_match_conciseness == 0) & (nb_of_match_unconciseness == 0):\n",
    "            conciseness_pred[i] = 0.5\n",
    "        elif (nb_of_match_conciseness > 0) & (nb_of_match_unconciseness > 0) :\n",
    "            conciseness_pred[i] = \\\n",
    "                    nb_of_match_conciseness * 1.0 / (nb_of_match_conciseness + nb_of_match_unconciseness)\n",
    "        elif (nb_of_match_conciseness > 0) & (nb_of_match_unconciseness == 0):\n",
    "            conciseness_pred[i] = 1\n",
    "        elif (nb_of_match_conciseness == 0) & (nb_of_match_unconciseness > 0):\n",
    "            conciseness_pred[i] = 0\n",
    "\n",
    "#     if clarities_pred[i] != row['clarity']:\n",
    "#         if categories_word_wrong_case_dict.get(full_category) == None:\n",
    "#             categories_word_wrong_case_dict[full_category] = 0\n",
    "#         categories_word_wrong_case_dict[full_category] += 1\n",
    "        \n",
    "#     if conciseness_pred[i] != row['conciseness']:\n",
    "#         if categories_word_wrong_case_conciseness_dict.get(full_category) == None:\n",
    "#             categories_word_wrong_case_conciseness_dict[full_category] = 0\n",
    "#         categories_word_wrong_case_conciseness_dict[full_category] += 1\n",
    "    \n",
    "    i = i + 1   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_error\n",
    "# clarity_error = np.sqrt(mean_squared_error(test_df.clarity.as_matrix(), clarities_pred))\n",
    "# conciseness_error = np.sqrt(mean_squared_error(test_df.conciseness.as_matrix(), conciseness_pred))\n",
    "\n",
    "# print(\"clarity_error: \", clarity_error)\n",
    "# print(\"conciseness_error: \", conciseness_error)\n",
    "# print(\"mean: \", np.mean([clarity_error, conciseness_error]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clarities_pred_df = pd.DataFrame(data = clarities_pred.tolist())\n",
    "clarities_pred_df.to_csv(\"clarities_pred.csv\", index = False)\n",
    "\n",
    "conciseness_pred_df = pd.DataFrame(data = conciseness_pred.tolist())\n",
    "conciseness_pred_df.to_csv(\"conciseness_pred.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
